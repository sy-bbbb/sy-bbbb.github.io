---
layout: page
title: Enhancing the Reading Experience on AR HMDs by Using Smartphones as Assistive Displays (VR ’23)
img: assets/img/vr23_conditions.png
importance: 2
category: research
---

This work explores using smartphones as assistive displays for AR HMDs to improve AR reading.

---

<details><summary>Abstract</summary>
    The reading experience on current augmented reality (AR) head mounted displays (HMDs) is often impeded by the devices’ low perceived resolution, translucency, and small field of view, especially in situations involving lengthy text. Although many researchers have proposed methods to resolve this issue, the inherent characteristics prevent these displays from delivering a readability on par with that of more traditional displays. As a solution, we explore the use of smartphones as assistive displays to AR HMDs. To validate the feasibility of our approach, we conducted a user study in which we compared a <i>smartphone-assisted hybrid interface</i> against using the <i>HMD only</i> for two different text lengths. The results demonstrate that the <i>hybrid interface</i> yields a lower task load regardless of the text length, although it does not improve task performance. Furthermore, the <i>hybrid interface</i> provides a better experience regarding user comfort, visual fatigue, and perceived readability. Based on these results, we claim that joining the spatial output capabilities of the HMD with the high-resolution display of the smartphone is a viable solution for improving the reading experience in AR. 
</details>
---

## Research Questions

RQ1. Does the _hybrid interface_ benefit the user in terms of task performance and perceived task load in an AR reading task?   
RQ2. Are the advantages of the _hybrid interface_ measurably bigger for longer text that requires scrolling on the HMD?  
<br>

## Study Design

#### Study Conditions

A 2 x 2 within-subjects design was employed, with **interface** (_HMD only_, _hybrid_) and **text length** (_short_: 300 words, no scrolling; _long_: 600 words, requiring scrolling) as independent variables.

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.html path="assets/img/vr23_conditions.png" title="study conditions" class="img-fluid rounded z-depth-1" %}
    </div>
</div>

#### Experimental Task

Participants performed a label-assigning task, reading text descriptions and matching them to corresponding objects. _Task performance_, _perceived task load_, _preference_, _subjective ratings_, and _qualitative feedback_ were collected.  

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.html path="assets/img/vr23_task.jpg" title="experimental task" class="img-fluid rounded z-depth-1" %}
    </div>
</div>  
<br>


## Results

Although task performance was not improved, the _hybrid interface_ reduced task load regardless of text length and offered benefits in comfort, visual fatigue, perceived readability, ease of use, learnability, and system understanding.  These benefits were further supported by qualitative feedback.

<div class="row justify-content-sm-center">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.html path="assets/img/vr23_rtlx.png" title="rtlx" class="img-fluid rounded z-depth-1" %}
        {% include figure.html path="assets/img/vr23_subjective.jpg" title="subjective results" class="img-fluid rounded z-depth-1" %}
    </div>
</div>

