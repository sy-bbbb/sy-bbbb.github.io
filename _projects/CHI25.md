---
layout: page
title: Smartphone Integration for AR Reading
# description: Hybrid user interfaces that use smartphones as supplementary displays to enhance reading in AR
img: assets/img/chi25_guideline.png
importance: 1
category: work
---
### AReading with Smartphones: Understanding the Trade-offs between Enhanced Legibility and Display Switching Costs in Hybrid AR Interfaces (CHI '25)
This research investigates the use of *hybrid user interfaces* to enhance text readability in augmented reality (AR) by combining optical see-through head-mounted displays with smartphones. While this integration can improve information legibility, it may also introduce display switching side effects. The extent to which these side effects hinder user experience and when the benefits outweigh drawbacks remain unclear. To address this gap, we conducted an empirical study (N=24) to evaluate how hybrid user interfaces affect AR reading tasks across different content distances, which induce varying levels of display switching. Our findings show that *hybrid user interfaces* offer significant readability benefits compared to using the *HMD only*, reducing mental and physical demands when reading text linked to content at closer distances. However, as the distance between displays increases, the compensatory behaviors users adopt to manage increased switching costs negate these benefits, making *hybrid user interfaces* less effective. Based on these findings, we suggest (1) using smartphones as supplementary displays for text in reading-intensive tasks, (2) implementing adaptive display positioning to minimize switching overhead in such scenarios, and (3) adjusting the smartphone's role based on content distance for less intensive reading tasks. These insights provide guidance for optimizing smartphone integration in hybrid interfaces and enhancing AR systems for reading applications. 

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.html path="assets/img/chi25_conditions.jpg" title="study conditions" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    Study conditions
</div>

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.html path="assets/img/chi25_behaviour.jpg" title="behavioural patterns" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    Behavioural patterns
</div>

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.html path="assets/img/chi25_guideline.png" title="design guidelines" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    Design guidelines for hybrid AR interfaces
</div>



### Enhancing the Reading Experience on AR HMDs by Using Smartphones as Assistive Displays (VR '23)
The reading experience on current augmented reality (AR) head mounted displays (HMDs) is often impeded by the devices' low perceived resolution, translucency, and small field of view, especially in situations involving lengthy text. Although many researchers have proposed methods to resolve this issue, the inherent characteristics prevent these displays from delivering a readability on par with that of more traditional displays. As a solution, we explore the use of smartphones as assistive displays to AR HMDs. To validate the feasibility of our approach, we conducted a user study in which we compared a smartphone-assisted *hybrid* interface against using the *HMD only* for two different text lengths. The results demonstrate that the *hybrid* interface yields a lower task load regardless of the text length, although it does not improve task performance. Furthermore, the *hybrid* interface provides a better experience regarding user comfort, visual fatigue, and perceived readability. Based on these results, we claim that joining the spatial output capabilities of the HMD with the high-resolution display of the smartphone is a viable solution for improving the reading experience in AR.

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.html path="assets/img/vr23_conditions.png" title="study conditions" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    Study conditions
</div>

<div class="row justify-content-sm-center">
    <div class="col-sm-4 mt-3 mt-md-0">
        {% include figure.html path="assets/img/vr23_task.png" title="study task" class="img-fluid rounded z-depth-1" %}
    </div>
    <div class="col-sm-8 mt-3 mt-md-0">
        {% include figure.html path="assets/img/vr23_rtlx.png" title="results" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    On the left is the experimental task. Right image shows the results for perceived workload.
</div>




